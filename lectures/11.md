# Lecture 11

## More on Big-O

Big-O is a function relating work done by algorithm (measured in instructions,
each of which takes one processor cycle) based on how many elements there are given as input.

Since we are intrested in all sizes of input (and especially in larger sizes), we denote the size as n.

Big-O translates as :upper bound to the amount of work in a worst-case scenario"

How to computer Big-O:

1. We count the exact number of steps T(n)
	- The result is some polynomial, e.g. n^2+10n
2. We drop all but the most significant term of the polynomial - the n with the highest power. 
All lower powers and constants are ommitted.
The reason is the highest power is completely overshadows the growth from the lower powers.
E.g. n^2 grows i = 0						1 op
while i < N					n+incomparanly faster than n, 
to the point that n cannot catch up.

```
i = 0						1 op
while i < N					n+1 ops (n true, 1 false)
	found = false			1 op (*n)
	j = 0					1 op(*n)
	while j < n				n+1 ops (n true, 1 false)
		if a[i] == b[j]		1 op (*n*n)
			found = true	1 op(*n)
			break			1 op(*n)
		++j					1 op(*n*n)						
	if !found				1 op(*n)
		return false		1 op (once per program)
	++1						1 op (*n)
return true					1 op(once per program, exclusive with truen)
```

T(n) is the exact count;
O(n) is T(n) stripped of 

T(n) = 1 + 1 +n[1 + 1 + 1 + n(1 + 1) + 1 + 1 + 1 + 1] + 1 = 3n^2+10n+3 
*Computed a polynomial funciton that I will now prune of constants and lower powers of n.*
The reason I can do is is because the largest power of n will dominate the growth  of the number of steps when size increases enough.

Big-O definition: T(n) <= c*f(n) where T(n) is the exact count of computer steps,
c is a constant, f(N) is logn, n, n^2, n^3... 2^n

Translated to English: Our full-fledged polynomial will grow slower than just the largest term time a bigger times a bigger constant than it currently has.

Translated to intuition:

A particular power of n, multiplied by ANY constant grows slower than the next power of n!

1,000,000*n at some point will dip BELOW n^2 on the coordinate plaine.
At that point O(n^2) does more work than the 1,000,000n algorithm.

Computing Big-O practically:
1. Check if algotithm is recursive;
if so you may have to think a lot about how many times it calls itself.
2. Check all lines that are looks.
The nested loops most likely dominate the Big-O and directly translate to an answer, e.g. 2 nested loops going from 0 to n-1 mean the algorithm is O(n^2) even if there are many other single linear loops going from 0 to n-1.
3. Check that the loops steps and terminating conditions make them linear or not.

## Binary Search

```
n = A.size
left = 0
right = n - 1
while left <= right //Looks like 0(n) at first
	mid = (left + right) / 2
	if A[mid] == v
		return true
	if v < A[mid] right = mid - 1
		right = mid - 1
	else
		left = mid + 1
return false
```
