# Lecture 15

## More on Quicksort
Professor went over quicksort, again... O(n) of quicksort per invocation is O(n),
so the O(n) of quicksort is O(nlog(n))

### Best case
When the pivot ALWAYS splits the array into two halves! O(logn)

### Worst case
Forward-sorted array!
Every time we call QuickSortRec(), we only take care of 1 element! 
Here we would use insertion sort for fastest performance.

How do we fix this worst-case scenario, which should be relatively common because we have nearly-sorted data in the real world.

1. Pick the pivot at random.
This is practically reduce the worst-case occassions in the real world.
But the worst-case scenario is still in the same range of probability.

2. Pick a median-of-three or a median-of-five pivot:
Pick the elements at indices first, last and first+last/2.
Inspect them and return the median element.
This makes the worst case scenario "almost impossible."

```java
// How we would implement median-of-three:

// Instead of writing the line:
int p = last;
int p = selectPivotIndex(arr, first, last);

```

### Difference between Quicksort and Mergesort

MergeSort requires extra memory for all the merge steps.


## Sorting stability

A sorting algorithm is stable if elements which have the same sorting key retain their original order after sorting.

**Example(!):** 4 students â€” Alice(21), Bob(20), Cindy(20), Dave(19)

We can sort ascending on age in two ways: 

- Dave, Bob, Cindy, Alice
- Dave, Cindy, Bob, Alice.

The first sequence is the result of a stable sort because Cindy follows Bob in the original data and the sorted data.
This is useful when we have several criteria in a sequence. (Like sorting students on senioruty, then credits, then GPA)
